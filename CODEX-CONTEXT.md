# Conversation Wingman - AI Context File

## Project Overview
Real-time conversation assistant that listens to voice, transcribes with Whisper, and suggests natural responses using ChatGPT.

## Core Features
- ğŸ¤ Live audio transcription (OpenAI Whisper)
- ğŸ§  Context-aware response suggestions (ChatGPT)
- ğŸ’¾ Save favorite phrases (Supabase)
- ğŸ¯ Topic-based suggestions
- ğŸ“± Floating widget UI (React)

## Tech Stack
- **Frontend**: React + Vite + Tailwind CSS
- **Backend**: Node.js/Express (API endpoints)
- **Database**: Supabase (PostgreSQL + Auth)
- **AI**: OpenAI Whisper API + ChatGPT API
- **Deployment**: Vercel (frontend) + Railway (backend)

## Folder Structure
conversation-wingman/
â”œâ”€â”€ frontend/ # React app
â”œâ”€â”€ backend/ # Node.js API
â”œâ”€â”€ docs/ # Documentation
â””â”€â”€ CODEX-CONTEXT.md # This file


## API Endpoints Needed
- `POST /api/transcribe` - Audio to text
- `POST /api/suggest` - Generate 3 suggestions
- `GET/POST /api/favorites` - CRUD for saved phrases

## UI Components Needed
- FloatingWidget (main container)
- SuggestionList (shows 3 options)
- AudioRecorder (microphone input)
- SavedPhrases (favorites management)

## Environment Variables
- OPENAI_API_KEY
- SUPABASE_URL
- SUPABASE_ANON_KEY

## Development Notes for AI Assistant
- Keep components small and focused
- Use modern React hooks (useState, useEffect, useCallback)
- Implement debouncing for audio transcription
- Add error handling for API calls
- Make UI responsive and accessible

## Next Implementation Steps
1. âœ… Create repo and context
2. â³ Initialize React frontend
3. â³ Set up basic API structure
4. â³ Implement audio recording
5. â³ Add OpenAI integration
